# Docu-Chat API - RAG Document Q&A System

A FastAPI-based API that allows users to upload documents and ask questions about them using the RAG (Retrieval-Augmented Generation) pattern.

## ğŸ¯ Project Overview

The Docu-Chat API enables users to:
- Upload PDF documents
- Ask questions about the uploaded content
- Get AI-powered answers based on document context

## ğŸ›  Tech Stack

- **Backend**: FastAPI
- **Document Loading**: pdfplumber
- **Text Splitting**: Custom text splitter
- **Vector Database**: ChromaDB
- **Embedding Model**: Hugging Face Sentence-Transformer (all-MiniLM-L6-v2)
- **LLM**: OpenAI API
- **Data Validation**: Pydantic

## ğŸš€ Getting Started

### Prerequisites
- Python 3.11+
- Git

### Installation
1. Clone the repository:
   ```bash
   git clone <repository-url>
   cd Docu-Chat
   ```

2. Create virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On macOS/Linux
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Run the server:
   ```bash
   python main.py
   ```

5. Access the API:
   - API: `http://localhost:8000/`
   - Interactive docs: `http://localhost:8000/docs`
   - Health check: `http://localhost:8000/health`

## ğŸ“ Project Structure

```
Docu-Chat/
â”œâ”€â”€ main.py              # FastAPI application
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .gitignore          # Git ignore rules
â”œâ”€â”€ README.md           # This file
â””â”€â”€ venv/              # Virtual environment (ignored by git)
```

## ğŸ”§ Dependencies

- `fastapi==0.104.1` - Web framework
- `uvicorn[standard]==0.24.0` - ASGI server
- `chromadb==0.4.18` - Vector database
- `openai==1.3.7` - OpenAI API client
- `pdfplumber==0.10.3` - PDF text extraction
- `sentence-transformers==2.2.2` - Embedding models
- `pydantic==2.5.0` - Data validation
- `python-multipart==0.0.6` - File upload support

## ğŸ¯ API Endpoints (Planned)

### POST /upload/
Upload a PDF document for processing.

**Request:**
- `file`: PDF file (multipart/form-data)

**Response:**
```json
{
  "message": "Document uploaded successfully",
  "document_id": "uuid",
  "chunks_created": 42
}
```

### POST /chat/
Ask a question about uploaded documents.

**Request:**
```json
{
  "question": "What is the main topic of the document?",
  "document_id": "uuid"
}
```

**Response:**
```json
{
  "answer": "The main topic is...",
  "sources": ["chunk_1", "chunk_2"],
  "confidence": 0.85
}
```

## ğŸ” RAG Architecture

```
PDF Upload â†’ Text Extraction â†’ Text Chunking â†’ Embedding Generation â†’ Vector Storage
                                                                    â†“
User Question â†’ Question Embedding â†’ Vector Search â†’ Context Retrieval â†’ LLM Generation â†’ Answer
```

## ğŸ“ Development Notes

- Virtual environment is properly ignored by git
- Large files (PyTorch models) are excluded from repository
- Clean git history maintained
- Ready for collaborative development

## ğŸš§ Current Status

**Level 1 Complete** âœ…
- Basic FastAPI server running
- Dependencies installed
- Git repository properly configured

**Next Steps:**
- Begin Level 2: Create API endpoints and Pydantic models
- Implement placeholder logic for upload and chat endpoints

---

*Last updated: Level 1 completion*
